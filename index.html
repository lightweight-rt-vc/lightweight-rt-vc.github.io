<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Lightweight Voice Conversion</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 1200px;
      margin: 0 auto;
      padding: 20px;
      line-height: 1.6;
    }
    h1, h2 {
      text-align: left;
    }
    .authors {
      margin-top: 10px;
      font-size: 1rem;
    }
    .affiliations {
      margin-top: 5px;
      font-size: 0.9rem;
      color: #555;   /* subtle gray for secondary text */
    }
    .affiliations sup {
      margin-right: 4px;
    }
    .audio-grid {
      display: flex;
      flex-direction: column;
      gap: 20px;
      margin-top: 20px;
    }
    .audio-row {
      display: grid;
      grid-template-columns: repeat(5, 1fr);
      gap: 15px;
      align-items: center;
    }
    .audio-cell {
      display: flex;
      flex-direction: column;
      align-items: center;
      border: 1px solid #ddd;
      padding: 10px;
      box-sizing: border-box;
    }
    .audio-cell strong {
      margin-bottom: 10px;
      font-weight: normal;
    }
    .audio-cell audio {
      width: 100%;
    }
    @media (max-width: 900px) {
      .audio-row {
        grid-template-columns: 1fr 1fr;
      }
    }
  </style>
</head>
<body>
  <div id="content">
        <h1>A Lightweight Real-Time Voice Conversion Framework<small> <a href="" target="_blank">[arXiv]</a> <a href="https://github.com/abargum/lightweight-rt-vc" target="_blank">[code]</a></small></h1>        
        <h2>With Improved Speaker Matching</h2>
    
        <div class="authors">
        Anders R. Bargum<sup>1,2</sup>, Cumhur Erkut<sup>1</sup>, Simon Lajboschitz<sup>2</sup>, and Stefania Sefafin<sup>1</sup>
        </div>

        <div class="affiliations">
          <div><sup>1</sup> Aalborg University, Denmark</div>
          <div><sup>2</sup> Khora & Heka VR, Denmark</div>
        </div>

        <h3 id="abstract">Abstract</h3>

        <p>Recent advancements in speech generation and speech representation learning have facilitated the development of real-time, streamable voice conversion systems.
          While these systems achieve synthesis quality and linguistic consistency comparable to state-of-the-art offline models, they often fall short in maintaining speaker similarity, particularly for unseen speakers i.e. in zero-shot scenarios.
          In this work, we propose a novel real-time voice conversion pipeline designed to enhance target speaker matching.
          Our approach leverages dynamic speaker embeddings and speaker information disentanglement through information perturbation.
          Operating under low-latency and lightweight causal inference constraints, our model preserves input prosody and linguistic content.
          Experimental results, based on both objective and subjective evaluations, demonstrate improved speaker matching compared to existing solutions.</p>

        <br>
        <img src="overall_pipeline.png" alt="Pipeline Diagram" style="max-width:100%; height:auto; display:block; margin:20px auto;">
        <br>
  </div>
  <h1>Audio Comparison</h1>

  <!-- Table Header -->
  <div class="audio-row">
    <div class="audio-cell"><strong>Source</strong></div>
    <div class="audio-cell"><strong>Target</strong></div>
    <div class="audio-cell"><strong>Model 1</strong></div>
    <div class="audio-cell"><strong>Model 2</strong></div>
    <div class="audio-cell"><strong>Proposed</strong></div>
  </div>

  <!-- Example Row 1 -->
  <div class="audio-row">
    <div class="audio-cell">
      <audio controls>
        <source src="audio/source1.wav" type="audio/wav">
      </audio>
    </div>
    <div class="audio-cell">
      <audio controls>
        <source src="audio/target1.wav" type="audio/wav">
      </audio>
    </div>
    <div class="audio-cell">
      <audio controls>
        <source src="audio/model1_1.wav" type="audio/wav">
      </audio>
    </div>
    <div class="audio-cell">
      <audio controls>
        <source src="audio/model2_1.wav" type="audio/wav">
      </audio>
    </div>
    <div class="audio-cell">
      <audio controls>
        <source src="audio/proposed1.wav" type="audio/wav">
      </audio>
    </div>
  </div>

  <!-- Example Row 2 -->
  <div class="audio-row">
    <div class="audio-cell">
      <audio controls>
        <source src="audio/source2.wav" type="audio/wav">
      </audio>
    </div>
    <div class="audio-cell">
      <audio controls>
        <source src="audio/target2.wav" type="audio/wav">
      </audio>
    </div>
    <div class="audio-cell">
      <audio controls>
        <source src="audio/model1_2.wav" type="audio/wav">
      </audio>
    </div>
    <div class="audio-cell">
      <audio controls>
        <source src="audio/model2_2.wav" type="audio/wav">
      </audio>
    </div>
    <div class="audio-cell">
      <audio controls>
        <source src="audio/proposed2.wav" type="audio/wav">
      </audio>
    </div>
  </div>

  <!-- Add more rows as needed -->
</body>
</html>
